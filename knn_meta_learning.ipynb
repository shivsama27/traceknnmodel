{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Making sure the data is properly being loaded"
      ],
      "metadata": {
        "id": "5rquUST3vaIy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# 1. PROPERLY MOUNT DRIVE\n",
        "drive.flush_and_unmount()  # Clean previous mounts\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# 2. VERIFY PATH EXISTS\n",
        "data_dir = \"/content/drive/MyDrive/tracedata\"\n",
        "\n",
        "# Check if directory exists\n",
        "if not os.path.exists(data_dir):\n",
        "    print(f\"❌ Critical Error: Folder '{data_dir}' doesn't exist!\")\n",
        "    print(\"Do these EXACTLY:\")\n",
        "    print(\"1. Go to drive.google.com\")\n",
        "    print(\"2. Create folder 'tracedata' directly in 'My Drive' (NOT inside other folders)\")\n",
        "    print(\"3. Upload all CSV files to this folder\")\n",
        "    raise FileNotFoundError(f\"Path {data_dir} not found\")\n",
        "\n",
        "# 3. CHECK FILES IN DIRECTORY\n",
        "print(\"\\n✅ Folder exists. Contents:\")\n",
        "files = os.listdir(data_dir)\n",
        "print(f\"Found {len(files)} files:\")\n",
        "print(*files[:5], sep=\"\\n\")  # Show first 5 files\n",
        "\n",
        "# 4. LOAD DATA WITH ERROR HANDLING\n",
        "def safe_load_csv(directory):\n",
        "    csv_files = [f for f in os.listdir(directory) if f.endswith('.csv')]\n",
        "    if not csv_files:\n",
        "        raise ValueError(f\"No CSV files found in {directory}\")\n",
        "\n",
        "    print(\"\\nLoading CSV files:\")\n",
        "    dfs = []\n",
        "    for file in csv_files:\n",
        "        file_path = os.path.join(directory, file)\n",
        "        print(f\"- Loading {file}\")\n",
        "        try:\n",
        "            df = pd.read_csv(file_path)\n",
        "            dfs.append(df)\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Error loading {file}: {str(e)}\")\n",
        "\n",
        "    if not dfs:\n",
        "        raise ValueError(\"No CSV files could be loaded\")\n",
        "\n",
        "    return pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "# 5. EXECUTE WITH VERIFICATION\n",
        "try:\n",
        "    full_data = safe_load_csv(data_dir)\n",
        "    print(\"\\nSuccess! Data shape:\", full_data.shape)\n",
        "except Exception as e:\n",
        "    print(\"\\n❌ Loading failed:\", str(e))"
      ],
      "metadata": {
        "id": "YCZyhDTeUk2B",
        "outputId": "1ff439d2-2ed8-446b-8bb0-47ff27ea0943",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "\n",
            "✅ Folder exists. Contents:\n",
            "Found 21 files:\n",
            "1112_Sub01_walk_d10_1x1.csv\n",
            "1112_Sub01_walk_d10_0x7.csv\n",
            "1112_Sub01_walk_d10_0x9.csv\n",
            "1112_Sub01_walk_d5_0x9.csv\n",
            "1112_Sub01_walk_d5_0x7.csv\n",
            "\n",
            "Loading CSV files:\n",
            "- Loading 1112_Sub01_walk_d10_1x1.csv\n",
            "- Loading 1112_Sub01_walk_d10_0x7.csv\n",
            "- Loading 1112_Sub01_walk_d10_0x9.csv\n",
            "- Loading 1112_Sub01_walk_d5_0x9.csv\n",
            "- Loading 1112_Sub01_walk_d5_0x7.csv\n",
            "- Loading 0117_Sub01_SA_i33_02.csv\n",
            "- Loading 0117_Sub01_SD_d33_01.csv\n",
            "- Loading 0117_Sub01_SD_d33_03.csv\n",
            "- Loading 0117_Sub01_SA_i33_03.csv\n",
            "- Loading 0117_Sub01_SD_d33_02.csv\n",
            "- Loading 0117_Sub01_SA_i33_01.csv\n",
            "- Loading 1112_Sub01_walk_i5_0x9.csv\n",
            "- Loading 1112_Sub01_walk_i5_0x7.csv\n",
            "- Loading 1112_Sub01_walk_i10_1x1.csv\n",
            "- Loading 1112_Sub01_walk_i10_0x9.csv\n",
            "- Loading 1112_Sub01_walk_i10_0x7.csv\n",
            "- Loading 1112_Sub01_walk_d5_1x1.csv\n",
            "- Loading 1112_Sub01_walk_i0_1x3.csv\n",
            "- Loading 1112_Sub01_walk_i0_1x1.csv\n",
            "- Loading 1112_Sub01_walk_i0_0x9.csv\n",
            "- Loading 1112_Sub01_walk_i5_1x1.csv\n",
            "\n",
            "Success! Data shape: (188857, 25)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "KNN using the sklearn library - this is the most common library to use for the KNN model."
      ],
      "metadata": {
        "id": "4QzoARGaveS7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.flush_and_unmount()\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Custom Dataset Class\n",
        "class GaitPredictionDataset(Dataset):\n",
        "    def __init__(self, data, window_size=100, stride=20):\n",
        "        self.window_size = window_size\n",
        "        self.stride = stride\n",
        "\n",
        "        # Features: Joint angles\n",
        "        self.feature_cols = [\n",
        "            'left_hip_angle',\n",
        "            'left_knee_angle',\n",
        "            'right_hip_angle',\n",
        "            'right_knee_angle'\n",
        "        ]\n",
        "\n",
        "        # Targets: Prediction labels\n",
        "        self.target_cols = [\n",
        "            'locomotion_mode',\n",
        "            'terrain_info',\n",
        "            'gait_phase'\n",
        "        ]\n",
        "\n",
        "        # Validate columns\n",
        "        missing_features = [col for col in self.feature_cols if col not in data.columns]\n",
        "        missing_targets = [col for col in self.target_cols if col not in data.columns]\n",
        "\n",
        "        if missing_features:\n",
        "            raise ValueError(f\"Missing feature columns: {missing_features}\")\n",
        "        if missing_targets:\n",
        "            raise ValueError(f\"Missing target columns: {missing_targets}\")\n",
        "\n",
        "        self.features = data[self.feature_cols].values.astype(np.float32)\n",
        "        self.labels = data[self.target_cols].values\n",
        "        self.samples = self._create_windows()\n",
        "\n",
        "    def _create_windows(self):\n",
        "        windows = []\n",
        "        max_start = len(self.features) - self.window_size + 1\n",
        "        for i in range(0, max_start, self.stride):\n",
        "            window_features = self.features[i:i+self.window_size]\n",
        "            window_labels = self.labels[i+self.window_size-1]  # Last label in window\n",
        "            windows.append((window_features, window_labels))\n",
        "        return windows\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        features, labels = self.samples[idx]\n",
        "        return torch.FloatTensor(features), torch.FloatTensor(labels)\n",
        "\n",
        "# Meta-Learning KNN System\n",
        "class GaitKNNPredictor:\n",
        "    def __init__(self):\n",
        "        self.models = {\n",
        "            'locomotion': KNeighborsClassifier(n_neighbors=5),\n",
        "            'terrain': KNeighborsClassifier(n_neighbors=5),\n",
        "            'gait_phase': KNeighborsClassifier(n_neighbors=5)\n",
        "        }\n",
        "        self.encoders = {\n",
        "            'locomotion': LabelEncoder(),\n",
        "            'terrain': LabelEncoder(),\n",
        "            'gait_phase': LabelEncoder()\n",
        "        }\n",
        "\n",
        "    def train(self, X_train, y_locomotion, y_terrain, y_gait_phase):\n",
        "        # Encode categorical labels\n",
        "        y_locomotion_enc = self.encoders['locomotion'].fit_transform(y_locomotion)\n",
        "        y_terrain_enc = self.encoders['terrain'].fit_transform(y_terrain)\n",
        "        y_gait_enc = self.encoders['gait_phase'].fit_transform(y_gait_phase)\n",
        "\n",
        "        print(\"Training locomotion model...\")\n",
        "        self.models['locomotion'].fit(X_train, y_locomotion_enc)\n",
        "\n",
        "        print(\"Training terrain model...\")\n",
        "        self.models['terrain'].fit(X_train, y_terrain_enc)\n",
        "\n",
        "        print(\"Training gait phase model...\")\n",
        "        self.models['gait_phase'].fit(X_train, y_gait_enc)\n",
        "\n",
        "    def evaluate(self, X_test, y_locomotion, y_terrain, y_gait_phase):\n",
        "        results = {}\n",
        "\n",
        "        # Predict and decode labels\n",
        "        for target in ['locomotion', 'terrain', 'gait_phase']:\n",
        "            y_true = locals()[f\"y_{target}\"]\n",
        "            y_pred_enc = self.models[target].predict(X_test)\n",
        "            y_pred = self.encoders[target].inverse_transform(y_pred_enc)\n",
        "\n",
        "            acc = accuracy_score(y_true, y_pred)\n",
        "            report = classification_report(y_true, y_pred)\n",
        "            results[target] = {'accuracy': acc, 'report': report}\n",
        "\n",
        "        return results\n",
        "\n",
        "# ===== MAIN EXECUTION =====\n",
        "# Load data\n",
        "data_dir = \"/content/drive/MyDrive/tracedata\"\n",
        "all_files = [f for f in os.listdir(data_dir) if f.endswith('.csv')]\n",
        "full_data = pd.concat([pd.read_csv(os.path.join(data_dir, f)) for f in all_files])\n",
        "\n",
        "# Check data\n",
        "print(\"Data columns:\", full_data.columns.tolist())\n",
        "print(\"\\nSample data:\")\n",
        "print(full_data[['left_hip_angle', 'locomotion_mode', 'terrain_info', 'gait_phase']].head())\n",
        "\n",
        "# Create dataset\n",
        "dataset = GaitPredictionDataset(full_data, window_size=100, stride=20)\n",
        "print(f\"\\nCreated {len(dataset)} sliding window samples\")\n",
        "\n",
        "# Prepare training data\n",
        "X = np.array([x.numpy().flatten() for x, y in dataset])\n",
        "y_locomotion = np.array([y[0].item() for x, y in dataset])\n",
        "y_terrain = np.array([y[1].item() for x, y in dataset])\n",
        "y_gait = np.array([y[2].item() for x, y in dataset])\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_lo_train, y_lo_test = train_test_split(X, y_locomotion, test_size=0.2, random_state=42)\n",
        "_, _, y_tr_train, y_tr_test = train_test_split(X, y_terrain, test_size=0.2, random_state=42)\n",
        "_, _, y_ga_train, y_ga_test = train_test_split(X, y_gait, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train and evaluate\n",
        "predictor = GaitKNNPredictor()\n",
        "predictor.train(X_train, y_lo_train, y_tr_train, y_ga_train)\n",
        "results = predictor.evaluate(X_test, y_lo_test, y_tr_test, y_ga_test)\n",
        "\n",
        "# Display results\n",
        "print(\"\\n=== Evaluation Results ===\")\n",
        "for target in results:\n",
        "    print(f\"\\n{target.upper()} Model:\")\n",
        "    print(f\"Accuracy: {results[target]['accuracy']:.2%}\")\n",
        "    print(\"Classification Report:\")\n",
        "    print(results[target]['report'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6H4AY8-yrJUS",
        "outputId": "dcf649e0-97e9-4199-89bd-79a0c8f15c50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive not mounted, so nothing to flush and unmount.\n",
            "Mounted at /content/drive\n",
            "Data columns: ['locomotion_mode', 'terrain_info', 'walk_speed_info', 'gait_phase', 'gait_percentage', 'left_accel_x', 'left_accel_y', 'left_accel_z', 'left_gyro_x', 'left_gyro_y', 'left_gyro_z', 'right_accel_x', 'right_accel_y', 'right_accel_z', 'right_gyro_x', 'right_gyro_y', 'right_gyro_z', 'left_hip_angle', 'left_knee_angle', 'right_hip_angle', 'right_knee_angle', 'left_hip_angle_vel', 'left_knee_angle_vel', 'right_hip_angle_vel', 'right_knee_angle_vel']\n",
            "\n",
            "Sample data:\n",
            "   left_hip_angle  locomotion_mode  terrain_info  gait_phase\n",
            "0           59.94              201             5           1\n",
            "1           59.94              201             5           1\n",
            "2           59.94              201             5           1\n",
            "3           59.94              201             5           1\n",
            "4           59.94              201             5           1\n",
            "\n",
            "Created 9438 sliding window samples\n",
            "Training locomotion model...\n",
            "Training terrain model...\n",
            "Training gait phase model...\n",
            "\n",
            "=== Evaluation Results ===\n",
            "\n",
            "LOCOMOTION Model:\n",
            "Accuracy: 99.79%\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       100.0       1.00      1.00      1.00       367\n",
            "       201.0       1.00      1.00      1.00       761\n",
            "       202.0       1.00      1.00      1.00       696\n",
            "       301.0       1.00      0.98      0.99        41\n",
            "       302.0       0.92      1.00      0.96        23\n",
            "\n",
            "    accuracy                           1.00      1888\n",
            "   macro avg       0.98      0.99      0.99      1888\n",
            "weighted avg       1.00      1.00      1.00      1888\n",
            "\n",
            "\n",
            "TERRAIN Model:\n",
            "Accuracy: 99.58%\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       -33.0       0.92      1.00      0.96        23\n",
            "       -10.0       0.99      1.00      0.99       358\n",
            "        -5.0       1.00      0.99      0.99       338\n",
            "         0.0       1.00      0.99      1.00       367\n",
            "         5.0       0.99      1.00      1.00       354\n",
            "        10.0       1.00      1.00      1.00       407\n",
            "        33.0       1.00      0.98      0.99        41\n",
            "\n",
            "    accuracy                           1.00      1888\n",
            "   macro avg       0.99      0.99      0.99      1888\n",
            "weighted avg       1.00      1.00      1.00      1888\n",
            "\n",
            "\n",
            "GAIT_PHASE Model:\n",
            "Accuracy: 90.41%\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00         1\n",
            "         1.0       0.78      0.77      0.78       228\n",
            "         2.0       0.94      0.94      0.94       744\n",
            "         3.0       0.81      0.79      0.80       202\n",
            "         4.0       0.93      0.95      0.94       713\n",
            "\n",
            "    accuracy                           0.90      1888\n",
            "   macro avg       0.69      0.69      0.69      1888\n",
            "weighted avg       0.90      0.90      0.90      1888\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "KNN using the Pytorch library, had to create the KNN using Pytorch's distance functions."
      ],
      "metadata": {
        "id": "XZA-WU2rvlFf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.flush_and_unmount()\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Custom PyTorch Dataset\n",
        "class GaitDataset(Dataset):\n",
        "    def __init__(self, data, window_size=100, stride=20):\n",
        "        self.window_size = window_size\n",
        "        self.stride = stride\n",
        "\n",
        "        # Features and targets\n",
        "        self.feature_cols = [\n",
        "            'left_hip_angle',\n",
        "            'left_knee_angle',\n",
        "            'right_hip_angle',\n",
        "            'right_knee_angle'\n",
        "        ]\n",
        "        self.target_cols = [\n",
        "            'locomotion_mode',\n",
        "            'terrain_info',\n",
        "            'gait_phase'\n",
        "        ]\n",
        "\n",
        "        # Validate columns\n",
        "        missing_features = [col for col in self.feature_cols if col not in data.columns]\n",
        "        missing_targets = [col for col in self.target_cols if col not in data.columns]\n",
        "        if missing_features or missing_targets:\n",
        "            raise ValueError(f\"Missing columns: Features={missing_features}, Targets={missing_targets}\")\n",
        "\n",
        "        # Convert to numpy arrays\n",
        "        self.features = data[self.feature_cols].values.astype(np.float32)\n",
        "        self.labels = data[self.target_cols].values\n",
        "        self.samples = self._create_windows()\n",
        "\n",
        "    def _create_windows(self):\n",
        "        windows = []\n",
        "        max_start = len(self.features) - self.window_size + 1\n",
        "        for i in range(0, max_start, self.stride):\n",
        "            window_features = self.features[i:i+self.window_size]\n",
        "            window_labels = self.labels[i+self.window_size-1]  # Last label in window\n",
        "            windows.append((window_features, window_labels))\n",
        "        return windows\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        features, labels = self.samples[idx]\n",
        "        return torch.tensor(features, dtype=torch.float32), torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "# Custom KNN Model in PyTorch\n",
        "class PyTorchKNN:\n",
        "    def __init__(self, k=5):\n",
        "        self.k = k\n",
        "        self.X_train = None\n",
        "        self.y_train = None\n",
        "\n",
        "    def fit(self, X_train, y_train):\n",
        "        self.X_train = X_train\n",
        "        self.y_train = y_train\n",
        "\n",
        "    def predict(self, X_test):\n",
        "        predictions = []\n",
        "        for x in X_test:\n",
        "            # Compute L2 distance (Euclidean)\n",
        "            distances = torch.norm(self.X_train - x, dim=1)\n",
        "            # Get k-nearest neighbors\n",
        "            _, indices = torch.topk(distances, self.k, largest=False)\n",
        "            # Vote for the most common label\n",
        "            neighbor_labels = self.y_train[indices]\n",
        "            unique_labels, counts = torch.unique(neighbor_labels, return_counts=True)\n",
        "            pred_label = unique_labels[torch.argmax(counts)]\n",
        "            predictions.append(pred_label)\n",
        "        return torch.tensor(predictions)\n",
        "\n",
        "# Meta-Learning KNN Trainer\n",
        "class MetaKNN:\n",
        "    def __init__(self):\n",
        "        self.models = {\n",
        "            'locomotion': PyTorchKNN(k=5),\n",
        "            'terrain': PyTorchKNN(k=5),\n",
        "            'gait_phase': PyTorchKNN(k=5)\n",
        "        }\n",
        "        self.encoders = {\n",
        "            'locomotion': LabelEncoder(),\n",
        "            'terrain': LabelEncoder(),\n",
        "            'gait_phase': LabelEncoder()\n",
        "        }\n",
        "\n",
        "    def train(self, X_train, y_locomotion, y_terrain, y_gait_phase):\n",
        "        # Encode categorical labels\n",
        "        y_locomotion_enc = self.encoders['locomotion'].fit_transform(y_locomotion)\n",
        "        y_terrain_enc = self.encoders['terrain'].fit_transform(y_terrain)\n",
        "        y_gait_enc = self.encoders['gait_phase'].fit_transform(y_gait_phase)\n",
        "\n",
        "        # Convert to PyTorch tensors\n",
        "        X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "        y_locomotion_tensor = torch.tensor(y_locomotion_enc, dtype=torch.long)\n",
        "        y_terrain_tensor = torch.tensor(y_terrain_enc, dtype=torch.long)\n",
        "        y_gait_tensor = torch.tensor(y_gait_enc, dtype=torch.long)\n",
        "\n",
        "        # Train KNN models\n",
        "        print(\"Training locomotion model...\")\n",
        "        self.models['locomotion'].fit(X_train_tensor, y_locomotion_tensor)\n",
        "\n",
        "        print(\"Training terrain model...\")\n",
        "        self.models['terrain'].fit(X_train_tensor, y_terrain_tensor)\n",
        "\n",
        "        print(\"Training gait phase model...\")\n",
        "        self.models['gait_phase'].fit(X_train_tensor, y_gait_tensor)\n",
        "\n",
        "    def evaluate(self, X_test, y_locomotion, y_terrain, y_gait_phase):\n",
        "        results = {}\n",
        "\n",
        "        # Convert test data to PyTorch tensors\n",
        "        X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "\n",
        "        # Predict and decode labels\n",
        "        for target in ['locomotion', 'terrain', 'gait_phase']:\n",
        "            y_true = locals()[f\"y_{target}\"]\n",
        "            y_pred_enc = self.models[target].predict(X_test_tensor)\n",
        "            y_pred = self.encoders[target].inverse_transform(y_pred_enc.numpy())\n",
        "\n",
        "            acc = accuracy_score(y_true, y_pred)\n",
        "            results[target] = acc\n",
        "\n",
        "        return results\n",
        "\n",
        "# ===== MAIN EXECUTION =====\n",
        "# Load data\n",
        "data_dir = \"/content/drive/MyDrive/tracedata\"\n",
        "all_files = [f for f in os.listdir(data_dir) if f.endswith('.csv')]\n",
        "full_data = pd.concat([pd.read_csv(os.path.join(data_dir, f)) for f in all_files])\n",
        "\n",
        "# Create dataset\n",
        "dataset = GaitDataset(full_data, window_size=100, stride=20)\n",
        "print(f\"Created {len(dataset)} sliding window samples\")\n",
        "\n",
        "# Prepare training data\n",
        "X = np.array([x.numpy().flatten() for x, y in dataset])\n",
        "y_locomotion = np.array([y[0].item() for x, y in dataset])\n",
        "y_terrain = np.array([y[1].item() for x, y in dataset])\n",
        "y_gait = np.array([y[2].item() for x, y in dataset])\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_lo_train, y_lo_test = train_test_split(X, y_locomotion, test_size=0.2, random_state=42)\n",
        "_, _, y_tr_train, y_tr_test = train_test_split(X, y_terrain, test_size=0.2, random_state=42)\n",
        "_, _, y_ga_train, y_ga_test = train_test_split(X, y_gait, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train and evaluate\n",
        "meta_knn = MetaKNN()\n",
        "meta_knn.train(X_train, y_lo_train, y_tr_train, y_ga_train)\n",
        "results = meta_knn.evaluate(X_test, y_lo_test, y_tr_test, y_ga_test)\n",
        "\n",
        "# Display results\n",
        "print(\"\\n=== Evaluation Results ===\")\n",
        "for target, acc in results.items():\n",
        "    print(f\"{target.capitalize()} Accuracy: {acc:.2%}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVy7WEgru-CR",
        "outputId": "1b2d9b8c-0f30-419a-d7d9-9c8677d9808f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Created 9438 sliding window samples\n",
            "Training locomotion model...\n",
            "Training terrain model...\n",
            "Training gait phase model...\n",
            "\n",
            "=== Evaluation Results ===\n",
            "Locomotion Accuracy: 99.79%\n",
            "Terrain Accuracy: 99.58%\n",
            "Gait_phase Accuracy: 90.41%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "How this code works ->\n",
        "This program classifies human movement patterns based on joint angle data using a meta-learning approach with K-Nearest Neighbors (KNN). It processes gait data to predict three aspects of movement: locomotion mode (e.g., walking, running), terrain type (e.g., flat ground, stairs), and gait phase (e.g., stance, swing). The data is first preprocessed into sliding windows, and three separate KNN models are trained for each classification task. Instead of traditional learning, KNN memorizes training samples and classifies new data points by finding the k-nearest neighbors and assigning the most common label. The meta-learning aspect comes from using multiple specialized KNN models, allowing the system to adapt to different movement classification tasks without interference."
      ],
      "metadata": {
        "id": "n81_SxjVvUpF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "from google.colab import drive\n",
        "\n",
        "drive.flush_and_unmount()\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "class GaitDataset(Dataset):\n",
        "    def __init__(self, data, window_size=100, stride=20):\n",
        "        self.window_size = window_size\n",
        "        self.stride = stride\n",
        "        self.feature_cols = ['left_hip_angle', 'left_knee_angle', 'right_hip_angle', 'right_knee_angle']\n",
        "        self.target_col = 'terrain_info'\n",
        "        self.features = data[self.feature_cols].values.astype(np.float32)\n",
        "        self.labels = data[self.target_col].values\n",
        "        self.samples = self._create_windows()\n",
        "\n",
        "    def _create_windows(self):\n",
        "        windows = []\n",
        "        for i in range(0, len(self.features) - self.window_size + 1, self.stride):\n",
        "            windows.append((self.features[i:i+self.window_size], self.labels[i+self.window_size-1]))\n",
        "        return windows\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        features, label = self.samples[idx]\n",
        "        return torch.tensor(features, dtype=torch.float32), torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "class PyTorchKNN:\n",
        "    def __init__(self, k=5):\n",
        "        self.k = k\n",
        "\n",
        "    def fit(self, X_train, y_train):\n",
        "        self.X_train = X_train\n",
        "        self.y_train = y_train\n",
        "\n",
        "    def predict(self, X_test):\n",
        "        predictions = []\n",
        "        for x in X_test:\n",
        "            distances = torch.norm(self.X_train - x, dim=1)\n",
        "            _, indices = torch.topk(distances, self.k, largest=False)\n",
        "            neighbor_labels = self.y_train[indices]\n",
        "            unique_labels, counts = torch.unique(neighbor_labels, return_counts=True)\n",
        "            predictions.append(unique_labels[torch.argmax(counts)])\n",
        "        return torch.tensor(predictions)\n",
        "\n",
        "def train_and_evaluate_knn(X_train, X_test, y_train, y_test, accuracy_threshold=0.9):\n",
        "    knn = PyTorchKNN(k=5)\n",
        "    knn.fit(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.long))\n",
        "    iterations = 0\n",
        "    achieved_accuracy = 0.0\n",
        "    while achieved_accuracy < accuracy_threshold:\n",
        "        y_pred = knn.predict(torch.tensor(X_test, dtype=torch.float32)).numpy()\n",
        "        achieved_accuracy = accuracy_score(y_test, y_pred)\n",
        "        iterations += 1\n",
        "        if iterations > 100:  # Prevent infinite loops\n",
        "            break\n",
        "    print(f\"Iterations needed to reach {accuracy_threshold*100:.2f}% accuracy: {iterations}\")\n",
        "    print(\"Predicted terrain incline values:\", y_pred)\n",
        "    return achieved_accuracy\n",
        "\n",
        "data_dir = \"/content/drive/MyDrive/tracedata\"\n",
        "all_files = [f for f in os.listdir(data_dir) if f.endswith('.csv')]\n",
        "full_data = pd.concat([pd.read_csv(os.path.join(data_dir, f)) for f in all_files])\n",
        "\n",
        "dataset = GaitDataset(full_data, window_size=100, stride=20)\n",
        "X = np.array([x.numpy().flatten() for x, y in dataset])\n",
        "y = np.array([y.item() for x, y in dataset])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "final_accuracy = train_and_evaluate_knn(X_train, X_test, y_train, y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHgdU7ioCyU8",
        "outputId": "b53093c1-1503-45c2-d046-7dc9308a5cd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Iterations needed to reach 90.00% accuracy: 1\n",
            "Predicted terrain incline values: [ 5 10 10 ...  0 10 10]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load data\n",
        "data_dir = \"/content/drive/MyDrive/tracedata\"\n",
        "all_files = [f for f in os.listdir(data_dir) if f.endswith('.csv')]\n",
        "full_data = pd.concat([pd.read_csv(os.path.join(data_dir, f)) for f in all_files])\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# Assuming dataset is already created and loaded\n",
        "# dataset = [...]  # Ensure dataset is properly initialized\n",
        "\n",
        "# Prepare training data\n",
        "X = np.array([x.numpy().flatten() for x, y in dataset])\n",
        "\n",
        "# Check if y is a tuple/list (multiple targets) or a single tensor\n",
        "if isinstance(dataset[0][1], (tuple, list)):\n",
        "    y_locomotion = np.array([y[0].item() for x, y in dataset])\n",
        "    y_terrain = np.array([y[1].item() for x, y in dataset])\n",
        "    y_gait = np.array([y[2].item() for x, y in dataset])\n",
        "else:\n",
        "    y_terrain = np.array([y.item() for x, y in dataset])  # Single target case\n",
        "\n",
        "\n",
        "# Check if y is a tuple/list (multiple targets) or a single tensor\n",
        "if isinstance(dataset[0][1], (tuple, list)):\n",
        "    y_locomotion = np.array([y[0].item() for x, y in dataset])\n",
        "    y_terrain = np.array([y[1].item() for x, y in dataset])\n",
        "    y_gait = np.array([y[2].item() for x, y in dataset])\n",
        "else:\n",
        "    y_terrain = np.array([y.item() for x, y in dataset])  # Single target case\n",
        "\n",
        "# Create dataset\n",
        "dataset = GaitDataset(full_data, window_size=100, stride=20)\n",
        "print(f\"Created {len(dataset)} sliding window samples\")\n",
        "\n",
        "# Prepare training data\n",
        "X = np.array([x.numpy().flatten() for x, y in dataset])\n",
        "\n",
        "# Check if y is a tuple/list (multiple targets) or a single tensor\n",
        "if isinstance(dataset[0][1], (tuple, list)):\n",
        "    y_locomotion = np.array([y[0].item() for x, y in dataset])\n",
        "    y_terrain = np.array([y[1].item() for x, y in dataset])\n",
        "    y_gait = np.array([y[2].item() for x, y in dataset])\n",
        "else:\n",
        "    y_terrain = np.array([y.item() for x, y in dataset])  # Single target case\n",
        "\n",
        "\n",
        "# Print unique class distribution for terrain incline\n",
        "print(\"\\n=== Terrain Incline Class Distribution ===\")\n",
        "unique_classes, class_counts = np.unique(y_terrain, return_counts=True)\n",
        "for cls, count in zip(unique_classes, class_counts):\n",
        "    print(f\"Class {cls}: {count} samples\")\n",
        "\n",
        "# Ensure proper data splitting\n",
        "X_train, X_test, y_tr_train, y_tr_test = train_test_split(X, y_terrain, test_size=0.2, random_state=42, shuffle=True)\n",
        "\n",
        "# Train and evaluate\n",
        "meta_knn = MetaKNN()\n",
        "meta_knn.train(X_train, y_tr_train, y_tr_train, y_tr_train)  # Only training on terrain for debugging\n",
        "\n",
        "# Predictions\n",
        "y_pred_terrain = meta_knn.models['terrain'].predict(torch.tensor(X_test, dtype=torch.float32)).numpy()\n",
        "\n",
        "# Print Classification Report\n",
        "print(\"\\n=== Classification Report for Terrain Incline ===\")\n",
        "print(classification_report(y_tr_test, y_pred_terrain))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_tr_test, y_pred_terrain)\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=unique_classes, yticklabels=unique_classes)\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Confusion Matrix for Terrain Incline Prediction\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "-SzpsK5MDhWv",
        "outputId": "2c3d79b4-c945-4f82-8edf-44be9ef82a4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "a Tensor with 3 elements cannot be converted to Scalar",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-26c973e5f7b3>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0my_gait\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0my_terrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Single target case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-26c973e5f7b3>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0my_gait\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0my_terrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Single target case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: a Tensor with 3 elements cannot be converted to Scalar"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.flush_and_unmount()\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Custom PyTorch Dataset\n",
        "class GaitDataset(Dataset):\n",
        "    def __init__(self, data, window_size=100, stride=20):\n",
        "        self.window_size = window_size\n",
        "        self.stride = stride\n",
        "\n",
        "        # Features and targets\n",
        "        self.feature_cols = [\n",
        "            'left_hip_angle',\n",
        "            'left_knee_angle',\n",
        "            'right_hip_angle',\n",
        "            'right_knee_angle'\n",
        "        ]\n",
        "        self.target_cols = [\n",
        "            'locomotion_mode',\n",
        "            'terrain_info',\n",
        "            'gait_phase'\n",
        "        ]\n",
        "\n",
        "        # Validate columns\n",
        "        missing_features = [col for col in self.feature_cols if col not in data.columns]\n",
        "        missing_targets = [col for col in self.target_cols if col not in data.columns]\n",
        "        if missing_features or missing_targets:\n",
        "            raise ValueError(f\"Missing columns: Features={missing_features}, Targets={missing_targets}\")\n",
        "\n",
        "        # Convert to numpy arrays\n",
        "        self.features = data[self.feature_cols].values.astype(np.float32)\n",
        "        self.labels = data[self.target_cols].values\n",
        "        self.samples = self._create_windows()\n",
        "\n",
        "    def _create_windows(self):\n",
        "        windows = []\n",
        "        max_start = len(self.features) - self.window_size + 1\n",
        "        for i in range(0, max_start, self.stride):\n",
        "            window_features = self.features[i:i+self.window_size]\n",
        "            window_labels = self.labels[i+self.window_size-1]  # Last label in window\n",
        "            windows.append((window_features, window_labels))\n",
        "        return windows\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        features, labels = self.samples[idx]\n",
        "        return torch.tensor(features, dtype=torch.float32), torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "# Custom KNN Model in PyTorch\n",
        "class PyTorchKNN:\n",
        "    def __init__(self, k=5):\n",
        "        self.k = k\n",
        "        self.X_train = None\n",
        "        self.y_train = None\n",
        "\n",
        "    def fit(self, X_train, y_train):\n",
        "        self.X_train = X_train\n",
        "        self.y_train = y_train\n",
        "\n",
        "    def predict(self, X_test):\n",
        "        predictions = []\n",
        "        for x in X_test:\n",
        "            # Compute L2 distance (Euclidean)\n",
        "            distances = torch.norm(self.X_train - x, dim=1)\n",
        "            # Get k-nearest neighbors\n",
        "            _, indices = torch.topk(distances, self.k, largest=False)\n",
        "            # Vote for the most common label\n",
        "            neighbor_labels = self.y_train[indices]\n",
        "            unique_labels, counts = torch.unique(neighbor_labels, return_counts=True)\n",
        "            pred_label = unique_labels[torch.argmax(counts)]\n",
        "            predictions.append(pred_label)\n",
        "        return torch.tensor(predictions)\n",
        "\n",
        "# Meta-Learning KNN Trainer\n",
        "class MetaKNN:\n",
        "    def __init__(self):\n",
        "        self.models = {\n",
        "            'locomotion': PyTorchKNN(k=5),\n",
        "            'terrain': PyTorchKNN(k=5),\n",
        "            'gait_phase': PyTorchKNN(k=5)\n",
        "        }\n",
        "        self.encoders = {\n",
        "            'locomotion': LabelEncoder(),\n",
        "            'terrain': LabelEncoder(),\n",
        "            'gait_phase': LabelEncoder()\n",
        "        }\n",
        "\n",
        "    def train(self, X_train, y_locomotion, y_terrain, y_gait_phase, max_epochs=100, target_accuracy=0.9):\n",
        "        # Encode categorical labels\n",
        "        y_locomotion_enc = self.encoders['locomotion'].fit_transform(y_locomotion)\n",
        "        y_terrain_enc = self.encoders['terrain'].fit_transform(y_terrain)\n",
        "        y_gait_enc = self.encoders['gait_phase'].fit_transform(y_gait_phase)\n",
        "\n",
        "        # Convert to PyTorch tensors\n",
        "        X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "        y_locomotion_tensor = torch.tensor(y_locomotion_enc, dtype=torch.long)\n",
        "        y_terrain_tensor = torch.tensor(y_terrain_enc, dtype=torch.long)\n",
        "        y_gait_tensor = torch.tensor(y_gait_enc, dtype=torch.long)\n",
        "\n",
        "        # Train KNN models\n",
        "        for epoch in range(max_epochs):\n",
        "            print(f\"Epoch {epoch + 1}/{max_epochs}\")\n",
        "\n",
        "            print(\"Training locomotion model...\")\n",
        "            self.models['locomotion'].fit(X_train_tensor, y_locomotion_tensor)\n",
        "\n",
        "            print(\"Training terrain model...\")\n",
        "            self.models['terrain'].fit(X_train_tensor, y_terrain_tensor)\n",
        "\n",
        "            print(\"Training gait phase model...\")\n",
        "            self.models['gait_phase'].fit(X_train_tensor, y_gait_tensor)\n",
        "\n",
        "            # Evaluate\n",
        "            train_acc = self.evaluate(X_train, y_locomotion, y_terrain, y_gait_phase)\n",
        "            print(f\"Training Accuracy: {train_acc}\")\n",
        "\n",
        "            # Check for target accuracy\n",
        "            if all(acc >= target_accuracy for acc in train_acc.values()):\n",
        "                print(f\"Target accuracy achieved in {epoch + 1} epochs\")\n",
        "                break\n",
        "\n",
        "    def evaluate(self, X_test, y_locomotion, y_terrain, y_gait_phase):\n",
        "        results = {}\n",
        "\n",
        "        # Convert test data to PyTorch tensors\n",
        "        X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "\n",
        "        # Predict and decode labels\n",
        "        for target in ['locomotion', 'terrain', 'gait_phase']:\n",
        "            y_true = locals()[f\"y_{target}\"]\n",
        "            y_pred_enc = self.models[target].predict(X_test_tensor)\n",
        "            y_pred = self.encoders[target].inverse_transform(y_pred_enc.numpy())\n",
        "\n",
        "            acc = accuracy_score(y_true, y_pred)\n",
        "            results[target] = acc\n",
        "\n",
        "        return results\n",
        "\n",
        "# ===== MAIN EXECUTION =====\n",
        "# Load data\n",
        "data_dir = \"/content/drive/MyDrive/tracedata\"\n",
        "all_files = [f for f in os.listdir(data_dir) if f.endswith('.csv')]\n",
        "full_data = pd.concat([pd.read_csv(os.path.join(data_dir, f)) for f in all_files])\n",
        "\n",
        "# Create dataset\n",
        "dataset = GaitDataset(full_data, window_size=100, stride=20)\n",
        "print(f\"Created {len(dataset)} sliding window samples\")\n",
        "\n",
        "# Prepare training data\n",
        "X = np.array([x.numpy().flatten() for x, y in dataset])\n",
        "y_locomotion = np.array([y[0].item() for x, y in dataset])\n",
        "y_terrain = np.array([y[1].item() for x, y in dataset])\n",
        "y_gait = np.array([y[2].item() for x, y in dataset])\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_lo_train, y_lo_test = train_test_split(X, y_locomotion, test_size=0.2, random_state=42)\n",
        "_, _, y_tr_train, y_tr_test = train_test_split(X, y_terrain, test_size=0.2, random_state=42)\n",
        "_, _, y_ga_train, y_ga_test = train_test_split(X, y_gait, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train and evaluate\n",
        "meta_knn = MetaKNN()\n",
        "meta_knn.train(X_train, y_lo_train, y_tr_train, y_ga_train)\n",
        "results = meta_knn.evaluate(X_test, y_lo_test, y_tr_test, y_ga_test)\n",
        "\n",
        "# Display results\n",
        "print(\"\\n=== Evaluation Results ===\")\n",
        "for target, acc in results.items():\n",
        "    print(f\"{target.capitalize()} Accuracy: {acc:.2%}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqHXBytRHPwc",
        "outputId": "a4a23386-a801-4816-80c4-6e300d522c1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Created 9438 sliding window samples\n",
            "Epoch 1/100\n",
            "Training locomotion model...\n",
            "Training terrain model...\n",
            "Training gait phase model...\n",
            "Training Accuracy: {'locomotion': 0.9964238410596027, 'terrain': 0.9943046357615895, 'gait_phase': 0.9268874172185431}\n",
            "Target accuracy achieved in 1 epochs\n",
            "\n",
            "=== Evaluation Results ===\n",
            "Locomotion Accuracy: 99.79%\n",
            "Terrain Accuracy: 99.58%\n",
            "Gait_phase Accuracy: 90.41%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cross subject testing (two subjects). The epoch is 1 because it is not a neural network and does not iterate through. Run time is about 51 seconds."
      ],
      "metadata": {
        "id": "58H66q3YxVtM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.flush_and_unmount()\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Custom PyTorch Dataset\n",
        "class GaitDataset(Dataset):\n",
        "    def __init__(self, data, window_size=100, stride=20):\n",
        "        self.window_size = window_size\n",
        "        self.stride = stride\n",
        "\n",
        "        # Features and targets\n",
        "        self.feature_cols = [\n",
        "            'left_hip_angle',\n",
        "            'left_knee_angle',\n",
        "            'right_hip_angle',\n",
        "            'right_knee_angle'\n",
        "        ]\n",
        "        self.target_cols = [\n",
        "            'locomotion_mode',\n",
        "            'terrain_info',\n",
        "            'gait_phase'\n",
        "        ]\n",
        "\n",
        "        # Validate columns\n",
        "        missing_features = [col for col in self.feature_cols if col not in data.columns]\n",
        "        missing_targets = [col for col in self.target_cols if col not in data.columns]\n",
        "        if missing_features or missing_targets:\n",
        "            raise ValueError(f\"Missing columns: Features={missing_features}, Targets={missing_targets}\")\n",
        "\n",
        "        # Convert to numpy arrays\n",
        "        self.features = data[self.feature_cols].values.astype(np.float32)\n",
        "        self.labels = data[self.target_cols].values\n",
        "        self.samples = self._create_windows()\n",
        "\n",
        "    def _create_windows(self):\n",
        "        windows = []\n",
        "        max_start = len(self.features) - self.window_size + 1\n",
        "        for i in range(0, max_start, self.stride):\n",
        "            window_features = self.features[i:i+self.window_size]\n",
        "            window_labels = self.labels[i+self.window_size-1]  # Last label in window\n",
        "            windows.append((window_features, window_labels))\n",
        "        return windows\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        features, labels = self.samples[idx]\n",
        "        return torch.tensor(features, dtype=torch.float32), torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "# Custom KNN Model in PyTorch\n",
        "class PyTorchKNN:\n",
        "    def __init__(self, k=5):\n",
        "        self.k = k\n",
        "        self.X_train = None\n",
        "        self.y_train = None\n",
        "\n",
        "    def fit(self, X_train, y_train):\n",
        "        self.X_train = X_train\n",
        "        self.y_train = y_train\n",
        "\n",
        "    def predict(self, X_test):\n",
        "        predictions = []\n",
        "        for x in X_test:\n",
        "            # Compute L2 distance (Euclidean)\n",
        "            distances = torch.norm(self.X_train - x, dim=1)\n",
        "            # Get k-nearest neighbors\n",
        "            _, indices = torch.topk(distances, self.k, largest=False)\n",
        "            # Vote for the most common label\n",
        "            neighbor_labels = self.y_train[indices]\n",
        "            unique_labels, counts = torch.unique(neighbor_labels, return_counts=True)\n",
        "            pred_label = unique_labels[torch.argmax(counts)]\n",
        "            predictions.append(pred_label)\n",
        "        return torch.tensor(predictions)\n",
        "\n",
        "# Meta-Learning KNN Trainer\n",
        "class MetaKNN:\n",
        "    def __init__(self):\n",
        "        self.models = {\n",
        "            'locomotion': PyTorchKNN(k=5),\n",
        "            'terrain': PyTorchKNN(k=5),\n",
        "            'gait_phase': PyTorchKNN(k=5)\n",
        "        }\n",
        "        self.encoders = {\n",
        "            'locomotion': LabelEncoder(),\n",
        "            'terrain': LabelEncoder(),\n",
        "            'gait_phase': LabelEncoder()\n",
        "        }\n",
        "\n",
        "    def train(self, X_train, y_locomotion, y_terrain, y_gait_phase, max_epochs=100, target_accuracy=0.9):\n",
        "        # Encode categorical labels\n",
        "        y_locomotion_enc = self.encoders['locomotion'].fit_transform(y_locomotion)\n",
        "        y_terrain_enc = self.encoders['terrain'].fit_transform(y_terrain)\n",
        "        y_gait_enc = self.encoders['gait_phase'].fit_transform(y_gait_phase)\n",
        "\n",
        "        # Convert to PyTorch tensors\n",
        "        X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "        y_locomotion_tensor = torch.tensor(y_locomotion_enc, dtype=torch.long)\n",
        "        y_terrain_tensor = torch.tensor(y_terrain_enc, dtype=torch.long)\n",
        "        y_gait_tensor = torch.tensor(y_gait_enc, dtype=torch.long)\n",
        "\n",
        "        # Train KNN models\n",
        "        for epoch in range(max_epochs):\n",
        "            print(f\"Epoch {epoch + 1}/{max_epochs}\")\n",
        "\n",
        "            print(\"Training locomotion model...\")\n",
        "            self.models['locomotion'].fit(X_train_tensor, y_locomotion_tensor)\n",
        "\n",
        "            print(\"Training terrain model...\")\n",
        "            self.models['terrain'].fit(X_train_tensor, y_terrain_tensor)\n",
        "\n",
        "            print(\"Training gait phase model...\")\n",
        "            self.models['gait_phase'].fit(X_train_tensor, y_gait_tensor)\n",
        "\n",
        "            # Evaluate\n",
        "            train_acc = self.evaluate(X_train, y_locomotion, y_terrain, y_gait_phase)\n",
        "            print(f\"Training Accuracy: {train_acc}\")\n",
        "\n",
        "            # Check for target accuracy\n",
        "            if all(acc >= target_accuracy for acc in train_acc.values()):\n",
        "                print(f\"Target accuracy achieved in {epoch + 1} epochs\")\n",
        "                break\n",
        "\n",
        "    def evaluate(self, X_test, y_locomotion, y_terrain, y_gait_phase):\n",
        "        results = {}\n",
        "\n",
        "        # Convert test data to PyTorch tensors\n",
        "        X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "\n",
        "        # Predict and decode labels\n",
        "        for target in ['locomotion', 'terrain', 'gait_phase']:\n",
        "            y_true = locals()[f\"y_{target}\"]\n",
        "            y_pred_enc = self.models[target].predict(X_test_tensor)\n",
        "            y_pred = self.encoders[target].inverse_transform(y_pred_enc.numpy())\n",
        "\n",
        "            acc = accuracy_score(y_true, y_pred)\n",
        "            results[target] = acc\n",
        "\n",
        "        return results\n",
        "\n",
        "    def save_predictions(self, X_test, output_path):\n",
        "        # Convert test data to PyTorch tensors\n",
        "        X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "\n",
        "        # Predict and decode labels\n",
        "        terrain_preds = self.models['terrain'].predict(X_test_tensor)\n",
        "        terrain_preds_decoded = self.encoders['terrain'].inverse_transform(terrain_preds.numpy())\n",
        "\n",
        "        # Save to Excel\n",
        "        df = pd.DataFrame({'Incline Prediction': terrain_preds_decoded})\n",
        "        df.to_excel(output_path, index=False)\n",
        "\n",
        "# ===== MAIN EXECUTION =====\n",
        "# Load data\n",
        "data_dir = \"/content/drive/MyDrive/tracedata1\"\n",
        "all_files = [f for f in os.listdir(data_dir) if f.endswith('.csv')]\n",
        "full_data = pd.concat([pd.read_csv(os.path.join(data_dir, f)) for f in all_files])\n",
        "\n",
        "# Create dataset\n",
        "dataset = GaitDataset(full_data, window_size=100, stride=20)\n",
        "print(f\"Created {len(dataset)} sliding window samples\")\n",
        "\n",
        "# Prepare training data\n",
        "X = np.array([x.numpy().flatten() for x, y in dataset])\n",
        "y_locomotion = np.array([y[0].item() for x, y in dataset])\n",
        "y_terrain = np.array([y[1].item() for x, y in dataset])\n",
        "y_gait = np.array([y[2].item() for x, y in dataset])\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_lo_train, y_lo_test = train_test_split(X, y_locomotion, test_size=0.2, random_state=42)\n",
        "_, _, y_tr_train, y_tr_test = train_test_split(X, y_terrain, test_size=0.2, random_state=42)\n",
        "_, _, y_ga_train, y_ga_test = train_test_split(X, y_gait, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train and evaluate\n",
        "meta_knn = MetaKNN()\n",
        "meta_knn.train(X_train, y_lo_train, y_tr_train, y_ga_train)\n",
        "results = meta_knn.evaluate(X_test, y_lo_test, y_tr_test, y_ga_test)\n",
        "\n",
        "# Display results\n",
        "print(\"\\n=== Evaluation Results ===\")\n",
        "for target, acc in results.items():\n",
        "    print(f\"{target.capitalize()} Accuracy: {acc:.2%}\")\n",
        "\n",
        "# Save predictions to Excel\n",
        "output_path = \"/content/drive/MyDrive/incline_predictions.xlsx\"\n",
        "meta_knn.save_predictions(X_test, output_path)\n",
        "print(f\"Predictions saved to {output_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fxOoPfaIRAD",
        "outputId": "4ace0313-95c8-4960-c609-a31464108a67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive not mounted, so nothing to flush and unmount.\n",
            "Mounted at /content/drive\n",
            "Created 18779 sliding window samples\n",
            "Epoch 1/100\n",
            "Training locomotion model...\n",
            "Training terrain model...\n",
            "Training gait phase model...\n",
            "Training Accuracy: {'locomotion': 0.9874192904213539, 'terrain': 0.9829594621580243, 'gait_phase': 0.9293083937961792}\n",
            "Target accuracy achieved in 1 epochs\n",
            "\n",
            "=== Evaluation Results ===\n",
            "Locomotion Accuracy: 97.82%\n",
            "Terrain Accuracy: 97.02%\n",
            "Gait_phase Accuracy: 89.70%\n",
            "Predictions saved to /content/drive/MyDrive/incline_predictions.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cross subject testing (3 subjects)"
      ],
      "metadata": {
        "id": "3b_Fwd1Hxp1w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.flush_and_unmount()\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Custom PyTorch Dataset\n",
        "class GaitDataset(Dataset):\n",
        "    def __init__(self, data, window_size=100, stride=20):\n",
        "        self.window_size = window_size\n",
        "        self.stride = stride\n",
        "\n",
        "        # Features and targets\n",
        "        self.feature_cols = [\n",
        "            'left_hip_angle',\n",
        "            'left_knee_angle',\n",
        "            'right_hip_angle',\n",
        "            'right_knee_angle'\n",
        "        ]\n",
        "        self.target_cols = [\n",
        "            'locomotion_mode',\n",
        "            'terrain_info',\n",
        "            'gait_phase'\n",
        "        ]\n",
        "\n",
        "        # Validate columns\n",
        "        missing_features = [col for col in self.feature_cols if col not in data.columns]\n",
        "        missing_targets = [col for col in self.target_cols if col not in data.columns]\n",
        "        if missing_features or missing_targets:\n",
        "            raise ValueError(f\"Missing columns: Features={missing_features}, Targets={missing_targets}\")\n",
        "\n",
        "        # Convert to numpy arrays\n",
        "        self.features = data[self.feature_cols].values.astype(np.float32)\n",
        "        self.labels = data[self.target_cols].values\n",
        "        self.samples = self._create_windows()\n",
        "\n",
        "    def _create_windows(self):\n",
        "        windows = []\n",
        "        max_start = len(self.features) - self.window_size + 1\n",
        "        for i in range(0, max_start, self.stride):\n",
        "            window_features = self.features[i:i+self.window_size]\n",
        "            window_labels = self.labels[i+self.window_size-1]  # Last label in window\n",
        "            windows.append((window_features, window_labels))\n",
        "        return windows\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        features, labels = self.samples[idx]\n",
        "        return torch.tensor(features, dtype=torch.float32), torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "# Custom KNN Model in PyTorch\n",
        "class PyTorchKNN:\n",
        "    def __init__(self, k=5):\n",
        "        self.k = k\n",
        "        self.X_train = None\n",
        "        self.y_train = None\n",
        "\n",
        "    def fit(self, X_train, y_train):\n",
        "        self.X_train = X_train\n",
        "        self.y_train = y_train\n",
        "\n",
        "    def predict(self, X_test):\n",
        "        predictions = []\n",
        "        for x in X_test:\n",
        "            # Compute L2 distance (Euclidean)\n",
        "            distances = torch.norm(self.X_train - x, dim=1)\n",
        "            # Get k-nearest neighbors\n",
        "            _, indices = torch.topk(distances, self.k, largest=False)\n",
        "            # Vote for the most common label\n",
        "            neighbor_labels = self.y_train[indices]\n",
        "            unique_labels, counts = torch.unique(neighbor_labels, return_counts=True)\n",
        "            pred_label = unique_labels[torch.argmax(counts)]\n",
        "            predictions.append(pred_label)\n",
        "        return torch.tensor(predictions)\n",
        "\n",
        "# Meta-Learning KNN Trainer\n",
        "class MetaKNN:\n",
        "    def __init__(self):\n",
        "        self.models = {\n",
        "            'locomotion': PyTorchKNN(k=5),\n",
        "            'terrain': PyTorchKNN(k=5),\n",
        "            'gait_phase': PyTorchKNN(k=5)\n",
        "        }\n",
        "        self.encoders = {\n",
        "            'locomotion': LabelEncoder(),\n",
        "            'terrain': LabelEncoder(),\n",
        "            'gait_phase': LabelEncoder()\n",
        "        }\n",
        "\n",
        "    def train(self, X_train, y_locomotion, y_terrain, y_gait_phase, max_epochs=100, target_accuracy=0.9):\n",
        "        # Encode categorical labels\n",
        "        y_locomotion_enc = self.encoders['locomotion'].fit_transform(y_locomotion)\n",
        "        y_terrain_enc = self.encoders['terrain'].fit_transform(y_terrain)\n",
        "        y_gait_enc = self.encoders['gait_phase'].fit_transform(y_gait_phase)\n",
        "\n",
        "        # Convert to PyTorch tensors\n",
        "        X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "        y_locomotion_tensor = torch.tensor(y_locomotion_enc, dtype=torch.long)\n",
        "        y_terrain_tensor = torch.tensor(y_terrain_enc, dtype=torch.long)\n",
        "        y_gait_tensor = torch.tensor(y_gait_enc, dtype=torch.long)\n",
        "\n",
        "        # Train KNN models\n",
        "        for epoch in range(max_epochs):\n",
        "            print(f\"Epoch {epoch + 1}/{max_epochs}\")\n",
        "\n",
        "            print(\"Training locomotion model...\")\n",
        "            self.models['locomotion'].fit(X_train_tensor, y_locomotion_tensor)\n",
        "\n",
        "            print(\"Training terrain model...\")\n",
        "            self.models['terrain'].fit(X_train_tensor, y_terrain_tensor)\n",
        "\n",
        "            print(\"Training gait phase model...\")\n",
        "            self.models['gait_phase'].fit(X_train_tensor, y_gait_tensor)\n",
        "\n",
        "            # Evaluate\n",
        "            train_acc = self.evaluate(X_train, y_locomotion, y_terrain, y_gait_phase)\n",
        "            print(f\"Training Accuracy: {train_acc}\")\n",
        "\n",
        "            # Check for target accuracy\n",
        "            if all(acc >= target_accuracy for acc in train_acc.values()):\n",
        "                print(f\"Target accuracy achieved in {epoch + 1} epochs\")\n",
        "                break\n",
        "\n",
        "    def evaluate(self, X_test, y_locomotion, y_terrain, y_gait_phase):\n",
        "        results = {}\n",
        "\n",
        "        # Convert test data to PyTorch tensors\n",
        "        X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "\n",
        "        # Predict and decode labels\n",
        "        for target in ['locomotion', 'terrain', 'gait_phase']:\n",
        "            y_true = locals()[f\"y_{target}\"]\n",
        "            y_pred_enc = self.models[target].predict(X_test_tensor)\n",
        "            y_pred = self.encoders[target].inverse_transform(y_pred_enc.numpy())\n",
        "\n",
        "            acc = accuracy_score(y_true, y_pred)\n",
        "            results[target] = acc\n",
        "\n",
        "        return results\n",
        "\n",
        "    def save_predictions(self, X_test, output_path):\n",
        "        # Convert test data to PyTorch tensors\n",
        "        X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "\n",
        "        # Predict and decode labels\n",
        "        terrain_preds = self.models['terrain'].predict(X_test_tensor)\n",
        "        terrain_preds_decoded = self.encoders['terrain'].inverse_transform(terrain_preds.numpy())\n",
        "\n",
        "        # Save to Excel\n",
        "        df = pd.DataFrame({'Incline Prediction': terrain_preds_decoded})\n",
        "        df.to_excel(output_path, index=False)\n",
        "\n",
        "# ===== MAIN EXECUTION =====\n",
        "# Load data\n",
        "data_dir = \"/content/drive/MyDrive/tracedata1\"\n",
        "all_files = [f for f in os.listdir(data_dir) if f.endswith('.csv')]\n",
        "full_data = pd.concat([pd.read_csv(os.path.join(data_dir, f)) for f in all_files])\n",
        "\n",
        "# Create dataset\n",
        "dataset = GaitDataset(full_data, window_size=100, stride=20)\n",
        "print(f\"Created {len(dataset)} sliding window samples\")\n",
        "\n",
        "# Prepare training data\n",
        "X = np.array([x.numpy().flatten() for x, y in dataset])\n",
        "y_locomotion = np.array([y[0].item() for x, y in dataset])\n",
        "y_terrain = np.array([y[1].item() for x, y in dataset])\n",
        "y_gait = np.array([y[2].item() for x, y in dataset])\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_lo_train, y_lo_test = train_test_split(X, y_locomotion, test_size=0.2, random_state=42)\n",
        "_, _, y_tr_train, y_tr_test = train_test_split(X, y_terrain, test_size=0.2, random_state=42)\n",
        "_, _, y_ga_train, y_ga_test = train_test_split(X, y_gait, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train and evaluate\n",
        "meta_knn = MetaKNN()\n",
        "meta_knn.train(X_train, y_lo_train, y_tr_train, y_ga_train)\n",
        "results = meta_knn.evaluate(X_test, y_lo_test, y_tr_test, y_ga_test)\n",
        "\n",
        "# Display results\n",
        "print(\"\\n=== Evaluation Results ===\")\n",
        "for target, acc in results.items():\n",
        "    print(f\"{target.capitalize()} Accuracy: {acc:.2%}\")\n",
        "\n",
        "# Save predictions to Excel\n",
        "output_path = \"/content/drive/MyDrive/incline_predictions.xlsx\"\n",
        "meta_knn.save_predictions(X_test, output_path)\n",
        "print(f\"Predictions saved to {output_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "808c0b57-29d3-42c5-ec41-fc6d8716fd66",
        "id": "6kNLhURRxn8A"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Created 26204 sliding window samples\n",
            "Epoch 1/100\n",
            "Training locomotion model...\n",
            "Training terrain model...\n",
            "Training gait phase model...\n",
            "Training Accuracy: {'locomotion': 0.9875017888660974, 'terrain': 0.9815389018747317, 'gait_phase': 0.9300195582693317}\n",
            "Target accuracy achieved in 1 epochs\n",
            "\n",
            "=== Evaluation Results ===\n",
            "Locomotion Accuracy: 98.00%\n",
            "Terrain Accuracy: 97.06%\n",
            "Gait_phase Accuracy: 89.85%\n",
            "Predictions saved to /content/drive/MyDrive/incline_predictions.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.flush_and_unmount()\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Custom PyTorch Dataset\n",
        "class GaitDataset(Dataset):\n",
        "    def __init__(self, data, window_size=100, stride=20):\n",
        "        self.window_size = window_size\n",
        "        self.stride = stride\n",
        "\n",
        "        # Features and targets\n",
        "        self.feature_cols = [\n",
        "            'left_hip_angle',\n",
        "            'left_knee_angle',\n",
        "            'right_hip_angle',\n",
        "            'right_knee_angle'\n",
        "        ]\n",
        "        self.target_cols = [\n",
        "            'locomotion_mode',\n",
        "            'terrain_info',\n",
        "            'gait_phase'\n",
        "        ]\n",
        "\n",
        "        # Validate columns\n",
        "        missing_features = [col for col in self.feature_cols if col not in data.columns]\n",
        "        missing_targets = [col for col in self.target_cols if col not in data.columns]\n",
        "        if missing_features or missing_targets:\n",
        "            raise ValueError(f\"Missing columns: Features={missing_features}, Targets={missing_targets}\")\n",
        "\n",
        "        # Convert to numpy arrays\n",
        "        self.features = data[self.feature_cols].values.astype(np.float32)\n",
        "        self.labels = data[self.target_cols].values\n",
        "        self.samples = self._create_windows()\n",
        "\n",
        "    def _create_windows(self):\n",
        "        windows = []\n",
        "        max_start = len(self.features) - self.window_size + 1\n",
        "        for i in range(0, max_start, self.stride):\n",
        "            window_features = self.features[i:i+self.window_size]\n",
        "            window_labels = self.labels[i+self.window_size-1]  # Last label in window\n",
        "            windows.append((window_features, window_labels))\n",
        "        return windows\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        features, labels = self.samples[idx]\n",
        "        return torch.tensor(features, dtype=torch.float32), torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "# Custom KNN Model in PyTorch\n",
        "class PyTorchKNN:\n",
        "    def __init__(self, k=5):\n",
        "        self.k = k\n",
        "        self.X_train = None\n",
        "        self.y_train = None\n",
        "\n",
        "    def fit(self, X_train, y_train):\n",
        "        self.X_train = X_train\n",
        "        self.y_train = y_train\n",
        "\n",
        "    def predict(self, X_test):\n",
        "        predictions = []\n",
        "        for x in X_test:\n",
        "            # Compute L2 distance (Euclidean)\n",
        "            distances = torch.norm(self.X_train - x, dim=1)\n",
        "            # Get k-nearest neighbors\n",
        "            _, indices = torch.topk(distances, self.k, largest=False)\n",
        "            # Vote for the most common label\n",
        "            neighbor_labels = self.y_train[indices]\n",
        "            unique_labels, counts = torch.unique(neighbor_labels, return_counts=True)\n",
        "            pred_label = unique_labels[torch.argmax(counts)]\n",
        "            predictions.append(pred_label)\n",
        "        return torch.tensor(predictions)\n",
        "\n",
        "# Meta-Learning KNN Trainer\n",
        "class MetaKNN:\n",
        "    def __init__(self):\n",
        "        self.models = {\n",
        "            'locomotion': PyTorchKNN(k=5),\n",
        "            'terrain': PyTorchKNN(k=5),\n",
        "            'gait_phase': PyTorchKNN(k=5)\n",
        "        }\n",
        "        self.encoders = {\n",
        "            'locomotion': LabelEncoder(),\n",
        "            'terrain': LabelEncoder(),\n",
        "            'gait_phase': LabelEncoder()\n",
        "        }\n",
        "\n",
        "    def train(self, X_train, y_locomotion, y_terrain, y_gait_phase, max_epochs=100, target_accuracy=0.9):\n",
        "        # Encode categorical labels\n",
        "        y_locomotion_enc = self.encoders['locomotion'].fit_transform(y_locomotion)\n",
        "        y_terrain_enc = self.encoders['terrain'].fit_transform(y_terrain)\n",
        "        y_gait_enc = self.encoders['gait_phase'].fit_transform(y_gait_phase)\n",
        "\n",
        "        # Convert to PyTorch tensors\n",
        "        X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "        y_locomotion_tensor = torch.tensor(y_locomotion_enc, dtype=torch.long)\n",
        "        y_terrain_tensor = torch.tensor(y_terrain_enc, dtype=torch.long)\n",
        "        y_gait_tensor = torch.tensor(y_gait_enc, dtype=torch.long)\n",
        "\n",
        "        # Train KNN models\n",
        "        for epoch in range(max_epochs):\n",
        "            print(f\"Epoch {epoch + 1}/{max_epochs}\")\n",
        "\n",
        "            print(\"Training locomotion model...\")\n",
        "            self.models['locomotion'].fit(X_train_tensor, y_locomotion_tensor)\n",
        "\n",
        "            print(\"Training terrain model...\")\n",
        "            self.models['terrain'].fit(X_train_tensor, y_terrain_tensor)\n",
        "\n",
        "            print(\"Training gait phase model...\")\n",
        "            self.models['gait_phase'].fit(X_train_tensor, y_gait_tensor)\n",
        "\n",
        "            # Evaluate\n",
        "            train_acc = self.evaluate(X_train, y_locomotion, y_terrain, y_gait_phase)\n",
        "            print(f\"Training Accuracy: {train_acc}\")\n",
        "\n",
        "            # Check for target accuracy\n",
        "            if all(acc >= target_accuracy for acc in train_acc.values()):\n",
        "                print(f\"Target accuracy achieved in {epoch + 1} epochs\")\n",
        "                break\n",
        "\n",
        "    def evaluate(self, X_test, y_locomotion, y_terrain, y_gait_phase):\n",
        "        results = {}\n",
        "\n",
        "        # Convert test data to PyTorch tensors\n",
        "        X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "\n",
        "        # Predict and decode labels\n",
        "        for target in ['locomotion', 'terrain', 'gait_phase']:\n",
        "            y_true = locals()[f\"y_{target}\"]\n",
        "            y_pred_enc = self.models[target].predict(X_test_tensor)\n",
        "            y_pred = self.encoders[target].inverse_transform(y_pred_enc.numpy())\n",
        "\n",
        "            acc = accuracy_score(y_true, y_pred)\n",
        "            results[target] = acc\n",
        "\n",
        "            # Confusion Matrix\n",
        "            cm = confusion_matrix(y_true, y_pred)\n",
        "            plt.figure(figsize=(8, 6))\n",
        "            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=self.encoders[target].classes_, yticklabels=self.encoders[target].classes_)\n",
        "            plt.title(f'Confusion Matrix for {target.capitalize()}')\n",
        "            plt.xlabel('Predicted')\n",
        "            plt.ylabel('True')\n",
        "            plt.show()\n",
        "\n",
        "        return results\n",
        "\n",
        "    def save_predictions(self, X_test, output_path):\n",
        "        # Convert test data to PyTorch tensors\n",
        "        X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "\n",
        "        # Predict and decode labels\n",
        "        terrain_preds = self.models['terrain'].predict(X_test_tensor)\n",
        "        terrain_preds_decoded = self.encoders['terrain'].inverse_transform(terrain_preds.numpy())\n",
        "\n",
        "        # Save to Excel\n",
        "        df = pd.DataFrame({'Incline Prediction': terrain_preds_decoded})\n",
        "        df.to_excel(output_path, index=False)\n",
        "\n",
        "# ===== MAIN EXECUTION =====\n",
        "# Load data\n",
        "data_dir = \"/content/drive/MyDrive/tracedata1\"\n",
        "all_files = [f for f in os.listdir(data_dir) if f.endswith('.csv')]\n",
        "full_data = pd.concat([pd.read_csv(os.path.join(data_dir, f)) for f in all_files])\n",
        "\n",
        "# Create dataset\n",
        "dataset = GaitDataset(full_data, window_size=100, stride=20)\n",
        "print(f\"Created {len(dataset)} sliding window samples\")\n",
        "\n",
        "# Prepare training data\n",
        "X = np.array([x.numpy().flatten() for x, y in dataset])\n",
        "y_locomotion = np.array([y[0].item() for x, y in dataset])\n",
        "y_terrain = np.array([y[1].item() for x, y in dataset])\n",
        "y_gait = np.array([y[2].item() for x, y in dataset])\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_lo_train, y_lo_test = train_test_split(X, y_locomotion, test_size=0.2, random_state=42)\n",
        "_, _, y_tr_train, y_tr_test = train_test_split(X, y_terrain, test_size=0.2, random_state=42)\n",
        "_, _, y_ga_train, y_ga_test = train_test_split(X, y_gait, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train and evaluate\n",
        "meta_knn = MetaKNN()\n",
        "meta_knn.train(X_train, y_lo_train, y_tr_train, y_ga_train)\n",
        "results = meta_knn.evaluate(X_test, y_lo_test, y_tr_test, y_ga_test)\n",
        "\n",
        "# Display results\n",
        "print(\"\\n=== Evaluation Results ===\")\n",
        "for target, acc in results.items():\n",
        "    print(f\"{target.capitalize()} Accuracy: {acc:.2%}\")\n",
        "\n",
        "# Save predictions to Excel\n",
        "output_path = \"/content/drive/MyDrive/incline_predictions.xlsx\"\n",
        "meta_knn.save_predictions(X_test, output_path)\n",
        "print(f\"Predictions saved to {output_path}\")\n",
        "\n",
        "# Plot Gait Phase and Incline Signals\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(full_data['gait_phase'], label='Gait Phase')\n",
        "plt.plot(full_data['terrain_info'], label='Incline')\n",
        "plt.title('Gait Phase and Incline Signals')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Value')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pk6i9kASwG4q",
        "outputId": "2e6af8e7-2f25-4123-bb4a-8aebf5710667"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive not mounted, so nothing to flush and unmount.\n",
            "Mounted at /content/drive\n",
            "Created 28554 sliding window samples\n",
            "Epoch 1/100\n",
            "Training locomotion model...\n",
            "Training terrain model...\n",
            "Training gait phase model...\n"
          ]
        }
      ]
    }
  ]
}